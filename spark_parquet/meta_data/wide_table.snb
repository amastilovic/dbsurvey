{
  "metadata" : {
    "name" : "wide_table",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null
  },
  "cells" : [ {
    "metadata" : {
      "id" : "49D9FC23689E486DB3C2406181009D93"
    },
    "cell_type" : "markdown",
    "source" : "# Spark & Parquet Example\n## WIDE TABLE\n### Create Parquet File"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "659731AD257F423F91798DE3C5388658"
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark._\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd._\nimport org.apache.spark.sql._\n\nval sparkSql = new SQLContext(sparkContext)\nimport sparkSql.implicits._\n\nval flatParquet = \"/opt/docker/notebooks/sightmachine/wide_table.parquet\"",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark._\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd._\nimport org.apache.spark.sql._\nsparkSql: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@9b184b3\nimport sparkSql.implicits._\nflatParquet: String = /opt/docker/notebooks/sightmachine/wide_table.parquet\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1,
      "time" : "Took: 2 seconds 856 milliseconds, at 2019-3-27 0:34"
    } ]
  }, {
    "metadata" : {
      "id" : "FEF3739435684B968A93AC827CC9A090"
    },
    "cell_type" : "markdown",
    "source" : "Create Table Schema in Spark"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "6BEA20EDEDA2456683397631F67F3D04"
    },
    "cell_type" : "code",
    "source" : "import java.sql.Timestamp\nimport org.apache.spark.sql.types._    \nimport scala.collection.mutable.ArrayBuffer\n\nval fields = new ArrayBuffer[StructField](3010)\nfields.+=(\n  StructField(\"HOST\", StringType, false),\n  StructField(\"DOMAIN\", StringType, false),\n  StructField(\"FEATURE\", StringType, false),\n  StructField(\"DATE\", TimestampType, false),\n  StructField(\"USAGE__CORE\", LongType, false),\n  StructField(\"USAGE__DB\", LongType, false)\n)\n\nvar i = 0\nfor(i <- 0 until 3000) {\n  fields.+=(\n      StructField(f\"FILLER__INT$i%04d\", IntegerType, false),\n      StructField(f\"FILLER__STR$i%04d\", StringType, false),\n      StructField(f\"FILLER__FLOAT$i%04d\", FloatType, false)\n  )\n}\n\nfields.+=(\n  StructField(\"STATS__ACTIVE_VISITOR\", IntegerType, false)\n)\n\nval WideTableFlat = StructType(fields)\n  \n\n//WideTableFlat.printTreeString",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import java.sql.Timestamp\nimport org.apache.spark.sql.types._\nimport scala.collection.mutable.ArrayBuffer\nfields: scala.collection.mutable.ArrayBuffer[org.apache.spark.sql.types.StructField] = ArrayBuffer(StructField(HOST,StringType,false), StructField(DOMAIN,StringType,false), StructField(FEATURE,StringType,false), StructField(DATE,TimestampType,false), StructField(USAGE__CORE,LongType,false), StructField(USAGE__DB,LongType,false), StructField(FILLER__INT0000,IntegerType,false), StructField(FILLER__STR0000,StringType,false), StructField(FILLER__FLOAT0000,FloatType,false), StructField(FILLER__INT0001,IntegerType,false), StructField(FILLER__STR0001,StringType,false), StructField(FILLER__FLOAT0001,FloatType,false), StructField(FILLER__INT0002,IntegerType,false), StructField(FILLER__STR000..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 2,
      "time" : "Took: 2 seconds 306 milliseconds, at 2019-3-27 0:34"
    } ]
  }, {
    "metadata" : {
      "id" : "050A4BCFEF824FE0979D5A47914C7CD5"
    },
    "cell_type" : "markdown",
    "source" : "Load CSV Data"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "F56F554FB30B4E029B6E8036FDF1684D"
    },
    "cell_type" : "code",
    "source" : "val csvfile = sparkSql.read\n                      .format(\"csv\")\n                      .option(\"delimiter\", \",\")\n                      .option(\"headers\", \"false\")\n                      .schema(WideTableFlat)\n                      .load(\"/opt/docker/notebooks/sightmachine/data/wide_table/WIDE_TABLE2.csv\")",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "csvfile: org.apache.spark.sql.DataFrame = [HOST: string, DOMAIN: string, FEATURE: string, DATE: timestamp, USAGE__CORE: bigint, USAGE__DB: bigint, FILLER__INT0000: int, FILLER__STR0000: string, FILLER__FLOAT0000: float, FILLER__INT0001: int, FILLER__STR0001: string, FILLER__FLOAT0001: float, FILLER__INT0002: int, FILLER__STR0002: string, FILLER__FLOAT0002: float, FILLER__INT0003: int, FILLER__STR0003: string, FILLER__FLOAT0003: float, FILLER__INT0004: int, FILLER__STR0004: string, FILLER__FLOAT0004: float, FILLER__INT0005: int, FILLER__STR0005: string, FILLER__FLOAT0005: float, FILLER__INT0006: int, FILLER__STR0006: string, FILLER__FLOAT0006: float, FILLER__INT0007: int, FILLER__STR0007: string, FILLER__FLOAT0007: float, FILLER__INT0008: int, FILLER__STR0008: string, FILLER__FLOAT0008: ..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 3,
      "time" : "Took: 1 second 290 milliseconds, at 2019-3-27 0:34"
    } ]
  }, {
    "metadata" : {
      "id" : "C34854B5A577479F99B23D9622A48329"
    },
    "cell_type" : "markdown",
    "source" : "Write Parquet Files"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "0B284B6A28664A4C99DB0DB7D7008765"
    },
    "cell_type" : "code",
    "source" : "// Hack to run shell commands\nimport sys.process._\n(\"rm -rf \" + flatParquet).!!\n\ncsvfile.write\n       .option(\"compression\", \"snappy\")\n       .parquet(flatParquet)\n\n(\"ls -l \" + flatParquet).!!",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "5D4F347A45F5480187B50C79C3E544CD"
    },
    "cell_type" : "markdown",
    "source" : "### Query Parquet File"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "FDAD554DCCF940FF8A44B203E3DBD4C2"
    },
    "cell_type" : "code",
    "source" : "val flatdf = sparkSql.read.parquet(flatParquet)\nflatdf.registerTempTable(\"WIDE_TABLE\")",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "flatdf: org.apache.spark.sql.DataFrame = [HOST: string, DOMAIN: string, FEATURE: string, DATE: timestamp, USAGE__CORE: bigint, USAGE__DB: bigint, STATS__ACTIVE_VISITOR: int]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 42,
      "time" : "Took: 813 milliseconds, at 2019-3-26 23:4"
    } ]
  }, {
    "metadata" : {
      "id" : "A79E597E690C48BE9707D49515FC7EB1"
    },
    "cell_type" : "markdown",
    "source" : "Average Usage by Domain"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "7D39B991EFE04C2B8FE51FD0502C460E"
    },
    "cell_type" : "code",
    "source" : "val query = \"\"\"\nSELECT DOMAIN, AVG(USAGE__CORE) Average_CPU_Usage, AVG(USAGE__DB) Average_DB_Usage \nFROM WEB_STAT \nGROUP BY DOMAIN \nORDER BY DOMAIN DESC\n\"\"\"\nsparkSql.sql(query)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "query: String = \n\"\nSELECT DOMAIN, AVG(USAGE__CORE) Average_CPU_Usage, AVG(USAGE__DB) Average_DB_Usage \nFROM WEB_STAT \nGROUP BY DOMAIN \nORDER BY DOMAIN DESC\n\"\nres61: org.apache.spark.sql.DataFrame = [DOMAIN: string, Average_CPU_Usage: double, Average_DB_Usage: double]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon3fdc6fdf40c800f4d2a9d748f9666ecd&quot;,&quot;partitionIndexId&quot;:&quot;anonc68b7e78805a630904fd4e35b36abcf0&quot;,&quot;numPartitions&quot;:1,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;DOMAIN&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Average_CPU_Usage&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Average_DB_Usage&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 34,
      "time" : "Took: 4 seconds 134 milliseconds, at 2019-3-26 23:2"
    } ]
  }, {
    "metadata" : {
      "id" : "ADDEDC64FD1B47DB8327B04C11D566E2"
    },
    "cell_type" : "markdown",
    "source" : "Sum, Min and Max CPU usage by Salesforce grouped by day"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "99FA5F9D95AA4751BAE81DD21D7A7F2C"
    },
    "cell_type" : "code",
    "source" : "val query = \"\"\"\nSELECT TRUNC(DATE,'DAY') DAY, SUM(USAGE__CORE) TOTAL_CPU_Usage, MIN(USAGE__CORE) MIN_CPU_Usage, MAX(USAGE__CORE) MAX_CPU_Usage,\n  MIN(FILLER__INT2404) RANDOM_INT_MIN, MAX(FILLER__INT2404) RANDOM_INT_MAX, MIN(FILLER__FLOAT0804) RANDOM_FLOAT_MIN, MAX(FILLER__FLOAT0804) RANDOM_FLOAT_MAX\nFROM WIDE_TABLE \nWHERE DOMAIN LIKE 'Salesforce%' \nGROUP BY TRUNC(DATE,'DAY')\n\"\"\"\nsparkSql.sql(query)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "query: String = \n\"\nSELECT TRUNC(DATE,'DAY') DAY, SUM(USAGE__CORE) TOTAL_CPU_Usage, MIN(USAGE__CORE) MIN_CPU_Usage, MAX(USAGE__CORE) MAX_CPU_Usage \nFROM WEB_STAT \nWHERE DOMAIN LIKE 'Salesforce%' \nGROUP BY TRUNC(DATE,'DAY')\n\"\nres65: org.apache.spark.sql.DataFrame = [DAY: date, TOTAL_CPU_Usage: bigint, MIN_CPU_Usage: bigint, MAX_CPU_Usage: bigint]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon844966fc2e99a5a43e583c95e396b1d1&quot;,&quot;partitionIndexId&quot;:&quot;anon1f476db0999d1b8df6d9141b7585fbdc&quot;,&quot;numPartitions&quot;:1,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;DAY&quot;,&quot;type&quot;:&quot;date&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;TOTAL_CPU_Usage&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;MIN_CPU_Usage&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;MAX_CPU_Usage&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 36,
      "time" : "Took: 4 seconds 16 milliseconds, at 2019-3-26 23:3"
    } ]
  }, {
    "metadata" : {
      "id" : "93DCBD1633504B47B72A5C057CA5F7FD"
    },
    "cell_type" : "markdown",
    "source" : "list host and total active users when core CPU usage is 10X greater than DB usage"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "D78D52747A0D4D9D8B332B691C118AA6"
    },
    "cell_type" : "code",
    "source" : "val query = \"\"\"\nSELECT HOST, SUM(STATS__ACTIVE_VISITOR) TOTAL_ACTIVE_VISITORS, SUM(FILLER__INT1404) RANDOM_INT_SUM, SUM(FILLER__FLOAT2804) RANDOM_FLOAT_SUM\nFROM WIDE_TABLE\nWHERE USAGE__DB > (USAGE__CORE * 10) \nGROUP BY HOST\n\"\"\"\nsparkSql.sql(query)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "query: String = \n\"\nSELECT HOST, SUM(STATS__ACTIVE_VISITOR) TOTAL_ACTIVE_VISITORS \nFROM WEB_STAT \nWHERE USAGE__DB > (USAGE__CORE * 10) \nGROUP BY HOST\n\"\nres77: org.apache.spark.sql.DataFrame = [HOST: string, TOTAL_ACTIVE_VISITORS: bigint]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon8bdfcac920495b71d93e29ebd466fec1&quot;,&quot;partitionIndexId&quot;:&quot;anonbac96dfddd1cf97206af71b4ca3ae338&quot;,&quot;numPartitions&quot;:1,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;HOST&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;TOTAL_ACTIVE_VISITORS&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 43,
      "time" : "Took: 3 seconds 424 milliseconds, at 2019-3-26 23:5"
    } ]
  } ],
  "nbformat" : 4
}